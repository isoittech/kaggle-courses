{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[中級機械学習ホームページ](https://www.kaggle.com/learn/intermediate-machine-learning)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**カテゴリ変数**をエンコードすることで、これまでで最良の結果が得られる！\n",
    "\n",
    "# セットアップ\n",
    "\n",
    "以下の質問は作業に対するフィードバックを提供する。フィードバックシステムを設定するために次のセルを実行しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle学習環境のコード確認設定\n",
    "# from learntools.core import binder\n",
    "# binder.bind(globals())\n",
    "# from learntools.ml_intermediate.ex3 import *\n",
    "# print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このエクササイズでは、[Kaggle学習ユーザー向け住宅価格コンペティション](https://www.kaggle.com/c/home-data-for-ml-course)のデータを使用する。\n",
    "\n",
    "![Ames住宅データセット画像](https://i.imgur.com/lTJVG4e.png)\n",
    "\n",
    "次のコードセルを変更せずに実行して、訓練セットと検証セットを`X_train`、`X_valid`、`y_train`、`y_valid`に読み込む。テストセットは`X_test`に読み込まれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88875.48s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  test.csv.gz  train.csv  train.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88880.62s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88885.76s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "88890.91s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "88896.05s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  test.csv.gz  train.csv  train.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# --- データファイルの展開と確認 ---\n",
    "#   データディレクトリ内のファイル一覧を表示する。\n",
    "!ls ./input/Housing-Prices \n",
    "!echo \"---------------\"\n",
    "# !gzip -d -c ./input/Housing-Prices/train.csv.gz > ./input/Housing-Prices/train.csv\n",
    "#   train.csv.gz（圧縮ファイル）を解凍してtrain.csvを作成する。\n",
    "!gzip -d -c ./input/Housing-Prices/train.csv.gz > ./input/Housing-Prices/train.csv\n",
    "# !gzip -d -c ./input/Housing-Prices/test.csv.gz > ./input/Housing-Prices/test.csv\n",
    "#   test.csv.gz（圧縮ファイル）を解凍してtest.csvを作成する。\n",
    "!gzip -d -c ./input/Housing-Prices/test.csv.gz > ./input/Housing-Prices/test.csv\n",
    "# !ls ./input/Housing-Prices\n",
    "#   再度ファイル一覧を表示し、解凍後のファイルが存在するか確認する。\n",
    "!ls ./input/Housing-Prices \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの読み込み\n",
    "# index_col='Id'でIDを行インデックスとして設定\n",
    "X = pd.read_csv('./input/Housing-Prices/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('./input/Housing-Prices/test.csv', index_col='Id')\n",
    "\n",
    "# 目的変数が欠損している行を削除し、目的変数と説明変数を分離\n",
    "# dropna: 欠損値を含む行を削除\n",
    "# axis=0: 行方向の削除\n",
    "# subset=['SalePrice']: SalePriceが欠損している行のみを対象\n",
    "# inplace=True: 元のデータフレームを変更\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "# 目的変数（住宅価格）を取り出す\n",
    "y = X.SalePrice\n",
    "# 説明変数から目的変数の列を削除\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# シンプルにするため、欠損値を含む列を削除\n",
    "# リスト内包表記を使用: X.columns内の各列colに対して、X[col].isnull().any()がTrueなら列名を取得\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# 訓練データから検証データを分割\n",
    "# train_size=0.8: 訓練データに80%を使用\n",
    "# test_size=0.2: 検証データに20%を使用\n",
    "# random_state=0: 再現性のための乱数シード\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のコードセルを使用して、データの最初の5行を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11694</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>6600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>13360</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13265</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                        \n",
       "619          20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
       "871          20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
       "93           30       RL    13360   Pave      IR1         HLS    AllPub   \n",
       "818          20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
       "303          20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "    LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "Id                                    ...                                       \n",
       "619    Inside       Gtl      NridgHt  ...         108             0         0   \n",
       "871    Inside       Gtl        NAmes  ...           0             0         0   \n",
       "93     Inside       Gtl      Crawfor  ...           0            44         0   \n",
       "818   CulDSac       Gtl      Mitchel  ...          59             0         0   \n",
       "303    Corner       Gtl      CollgCr  ...          81             0         0   \n",
       "\n",
       "    ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
       "Id                                                                         \n",
       "619         260         0        0       7    2007      New       Partial  \n",
       "871           0         0        0       8    2009       WD        Normal  \n",
       "93            0         0        0       8    2009       WD        Normal  \n",
       "818           0         0        0       7    2008       WD        Normal  \n",
       "303           0         0        0       1    2006       WD        Normal  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head()メソッドでデータフレームの先頭5行を表示\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットには数値変数とカテゴリ変数の両方が含まれていることに注目。モデルを訓練する前にカテゴリデータをエンコードする必要がある。\n",
    "\n",
    "異なるモデルを比較するために、チュートリアルと同じ`score_dataset()`関数を使用する。この関数はランダムフォレストモデルから[平均絶対誤差](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE)を報告する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 異なるアプローチを比較するための関数\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    # ランダムフォレスト回帰モデルを初期化（100本の決定木、乱数シード0）\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    # モデルを訓練データにフィット（学習）させる\n",
    "    model.fit(X_train, y_train)\n",
    "    # 検証データに対する予測を生成\n",
    "    preds = model.predict(X_valid)\n",
    "    # 予測値と実際の値の平均絶対誤差を計算して返す\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ1: カテゴリデータを含む列を削除する\n",
    "\n",
    "最も単純なアプローチから始める。以下のコードセルを使用して、`X_train`と`X_valid`のデータを前処理し、カテゴリデータを含む列を削除する。前処理されたDataFrameをそれぞれ`drop_X_train`と`drop_X_valid`に設定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データと検証データからカテゴリ列を削除\n",
    "# select_dtypes(exclude=['object'])で文字列型（オブジェクト型）の列を除外\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Kaggle環境での回答確認用コード（コメントアウト）\n",
    "# step_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_1.hint()\n",
    "#step_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このアプローチのMAEを取得するために次のコードセルを実行する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ2: ラベルエンコーディング\n",
    "\n",
    "## ラベルエンコーディングとは何か？\n",
    "\n",
    "ラベルエンコーディングは、カテゴリ変数（文字列）を数値に変換する手法である。\n",
    "例えば、['赤', '青', '緑'] というカテゴリを [0, 1, 2] という数値に変換する。\n",
    "\n",
    "なぜラベルエンコーディングが必要なのか？\n",
    "1. 多くの機械学習アルゴリズムは数値データしか扱えないため\n",
    "2. 文字列のままでは計算ができないため\n",
    "3. 特に決定木ベースのアルゴリズム（ランダムフォレストなど）では、\n",
    "   カテゴリ変数を数値に変換することで効率的に学習できる\n",
    "\n",
    "ラベルエンコーディングに進む前に、データセットを調査する。具体的には、`'Condition2'`列を見てみる。以下のコードセルは、訓練セットと検証セットの両方でのユニークな値を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "# unique()メソッドで列内のユニークな値を取得\n",
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、以下のコードを書いた場合：\n",
    "\n",
    "- 訓練データにラベルエンコーダーをフィットし、\n",
    "- それを使って訓練データと検証データの両方を変換する\n",
    "\n",
    "エラーが発生する。なぜこれが問題になるか分かるだろうか？（この質問に答えるには、上記の出力を使用する必要がある）\n",
    "\n",
    "上記の出力を見ると、訓練データと検証データで異なる値が含まれていることがわかる：\n",
    "\n",
    "- 訓練データには 'PosA', 'RRAe' が含まれている\n",
    "- 検証データには 'RRAn', 'RRNn' が含まれている\n",
    "\n",
    "これが問題になる理由：\n",
    "\n",
    "1. ラベルエンコーダーは訓練データに存在する値だけを学習する\n",
    "2. 検証データに訓練データにない値（'RRAn', 'RRNn'）が含まれていると、\n",
    "   エンコーダーはこれらの値に対応する数値を持っていないためエラーになる\n",
    "3. scikit-learn の LabelEncoder は未知のカテゴリに対して例外を発生させる設計になっている\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle環境でのヒント表示用（コメントアウト）\n",
    "# step_2.a.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle環境での解答表示用（コメントアウト）\n",
    "# step_2.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは実世界のデータでよく遭遇する一般的な問題であり、この問題を解決するためのアプローチは多数ある。例えば、新しいカテゴリに対応するカスタムラベルエンコーダーを作成することができる。しかし、最も単純なアプローチは、問題のあるカテゴリ列を削除することだ。\n",
    "\n",
    "この問題に対する可能な解決策：\n",
    "1. カスタムエンコーダーを作成し、未知の値に特別な数値（例：-1）を割り当てる\n",
    "2. 訓練データと検証/テストデータを結合してからエンコーディングする（データリーク注意）\n",
    "3. 問題のある列を削除する（情報損失のトレードオフ）\n",
    "\n",
    "ここでは単純さを優先して3番目のアプローチを採用する。なぜなら：\n",
    "- 実装が簡単で確実\n",
    "- 未知のカテゴリが将来も出現する可能性がある場合、根本的な解決になる\n",
    "- 多くの列がある場合、一部を削除しても全体のパフォーマンスへの影響は限定的\n",
    "\n",
    "以下のコードセルを実行して、問題のある列をPythonリスト`bad_label_cols`に保存する。同様に、安全にラベルエンコードできる列は`good_label_cols`に格納される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be label encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'BldgType', 'HouseStyle', 'ExterQual', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Utilities', 'ExterCond', 'Foundation', 'SaleType', 'Condition2', 'LandSlope', 'RoofMatl', 'Exterior2nd', 'HeatingQC', 'Neighborhood', 'Heating', 'Functional', 'Exterior1st', 'RoofStyle', 'Condition1']\n"
     ]
    }
   ],
   "source": [
    "# すべてのカテゴリ列\n",
    "# dtype == \"object\"でカテゴリ（文字列）型の列を特定\n",
    "# Pythonのリスト内包表記を使用して、データ型が「object」（文字列）の列だけを抽出している\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# 安全にラベルエンコードできる列\n",
    "# 訓練データと検証データで同じ値のセットを持つ列\n",
    "# なぜこの処理が必要か？\n",
    "# 1. set(X_train[col])：訓練データの特定の列に含まれるユニークな値の集合を取得\n",
    "# 2. set(X_valid[col])：検証データの同じ列に含まれるユニークな値の集合を取得\n",
    "# 3. 両者が等しい（==）場合、その列は安全にラベルエンコードできる\n",
    "#\n",
    "# 【重要な注意点】\n",
    "# 実際には、訓練データ ⊇ 検証データ（訓練データが検証データを包含）の関係であれば\n",
    "# 安全にラベルエンコードできる。なぜなら：\n",
    "# - 訓練データに存在する値だけが検証データにある場合、すべての値に対応する数値が存在する\n",
    "# - 訓練データに{'赤','青','緑','黄'}、検証データに{'赤','青'}のような場合も安全\n",
    "#\n",
    "# しかし、このコードでは完全一致（==）を条件としているため、より厳格な条件になっている。\n",
    "# より正確には以下のようなコードが適切：\n",
    "# good_label_cols = [col for col in object_cols if set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "#\n",
    "# 現在のコードは簡潔さを優先しているが、訓練データに余分な値がある場合も\n",
    "# 安全にエンコードできる可能性を排除している点に注意。\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# データセットから削除される問題のある列\n",
    "# 集合の差集合演算で、すべてのカテゴリ列から安全な列を引く\n",
    "# なぜこの処理をするのか？\n",
    "# 1. set(object_cols)：すべてのカテゴリ列の集合\n",
    "# 2. set(good_label_cols)：安全にエンコードできる列の集合\n",
    "# 3. 差集合演算（-）：1から2を引くことで、安全でない列だけを抽出\n",
    "# 4. list()で結果をリストに変換\n",
    "# 例：全カテゴリ列が{'色','形','サイズ','ブランド'}で、安全な列が{'色','形'}なら\n",
    "#    問題のある列は{'サイズ','ブランド'}となる\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコードセルを使用して、`X_train`と`X_valid`のデータをラベルエンコードする。前処理されたDataFrameをそれぞれ`label_X_train`と`label_X_valid`に設定する。\n",
    "\n",
    "ラベルエンコーディングの実装手順：\n",
    "1. 問題のある列（bad_label_cols）を削除する\n",
    "2. 安全な列（good_label_cols）に対してLabelEncoderを適用する\n",
    "3. 訓練データでエンコーダーをfit_transformし、検証データではtransformのみを行う\n",
    "\n",
    "なぜfit_transformとtransformを分けるのか？\n",
    "- fit_transform: エンコーダーがカテゴリと数値のマッピングを学習し、変換も行う\n",
    "- transform: 既に学習したマッピングを使って変換のみを行う\n",
    "\n",
    "これにより、訓練データと検証データで一貫したエンコーディングが保証される。\n",
    "例えば、訓練データで「赤」→0、「青」→1、「緑」→2と学習したら、\n",
    "検証データでも同じマッピングを適用する必要がある。\n",
    "\n",
    "- `bad_label_cols`のカテゴリ列をデータセットから削除するコードを提供している。\n",
    "- `good_label_cols`のカテゴリ列をラベルエンコードする必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# エンコードされないカテゴリ列を削除\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# ラベルエンコーダーを適用\n",
    "labelEncoder = LabelEncoder()\n",
    "for col in good_label_cols:\n",
    "    # 訓練データでエンコーダーをフィットし、変換\n",
    "    label_X_train[col] = labelEncoder.fit_transform(X_train[col])\n",
    "    # 検証データを変換（フィットはしない）\n",
    "    label_X_valid[col] = labelEncoder.transform(X_valid[col])\n",
    "    \n",
    "# Kaggle環境での回答確認用（コメントアウト）\n",
    "# step_2.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_2.b.hint()\n",
    "#step_2.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このアプローチのMAEを取得するために次のコードセルを実行する。\n",
    "\n",
    "ラベルエンコーディングの効果を評価する理由：\n",
    "1. カテゴリ変数を削除するアプローチ（ステップ1）と比較して、\n",
    "   情報を保持しながら数値化することでモデルの性能が向上するか確認する\n",
    "2. カテゴリ情報をモデルに取り込むことの重要性を定量的に評価する\n",
    "3. 後のステップで試すワンホットエンコーディングとの比較ベースラインを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Label Encoding):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17575.291883561644\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ3: カーディナリティの調査\n",
    "\n",
    "これまで、カテゴリ変数を扱うための2つの異なるアプローチを試した。そして、カテゴリデータをエンコードすることが、データセットから列を削除するよりも良い結果をもたらすことがわかった。\n",
    "\n",
    "なぜカテゴリデータのエンコードが列の削除より良いのか？\n",
    "1. 情報保持：カテゴリ変数には予測に役立つ情報が含まれている\n",
    "   - 例えば「Street」列の「Pave」か「Grvl」かという情報は住宅価格に影響する\n",
    "2. パターン認識：機械学習モデルはカテゴリ情報から重要なパターンを学習できる\n",
    "   - 特に決定木ベースのモデル（ランダムフォレスト）はカテゴリ変数を効果的に扱える\n",
    "3. 実証的結果：MAEの比較から、カテゴリ情報を保持する方が予測精度が向上することが確認できた\n",
    "   - ステップ1（削除）のMAE: 17837.83 vs ステップ2（ラベルエンコード）のMAE: 17575.29\n",
    "\n",
    "次に、ワンホットエンコーディングを試す。その前に、もう一つ追加のトピックをカバーする必要がある。まず、次のコードセルを変更せずに実行する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# カテゴリデータを持つ各列のユニークな値の数を取得\n",
    "# map関数で各列に対してnunique()を適用\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "# 列名とユニーク値数の辞書を作成\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# 列ごとのユニークな値の数を昇順で表示\n",
    "# sorted関数でキーの値（ユニーク値の数）に基づいてソート\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の出力は、カテゴリデータを持つ各列について、その列のユニークな値の数を示している。例えば、訓練データの`'Street'`列には、砂利道を表す`'Grvl'`と舗装道路を表す`'Pave'`という2つのユニークな値がある。\n",
    "\n",
    "カテゴリ変数のユニークな値の数を、そのカテゴリ変数の**カーディナリティ**と呼ぶ。例えば、`'Street'`変数のカーディナリティは2である。\n",
    "\n",
    "カーディナリティとは何か？\n",
    "- カテゴリ変数のユニークな値の数を「カーディナリティ」と呼ぶ\n",
    "- 例：'Street'列のカーディナリティは2（'Grvl'と'Pave'の2種類）\n",
    "- 'Neighborhood'列のカーディナリティは25（25種類の異なる地域名）\n",
    "\n",
    "なぜカーディナリティが重要なのか？\n",
    "1. エンコーディング方法の選択に影響する\n",
    "   - カーディナリティが低い→ワンホットエンコーディングが適切\n",
    "   - カーディナリティが高い→ラベルエンコーディングが効率的\n",
    "2. モデルの複雑さと学習効率に影響する\n",
    "   - カーディナリティが高いとモデルの複雑さが増し、過学習リスクも高まる\n",
    "3. データセットのサイズと計算コストに直接関わる\n",
    "   - 次のセクションで詳しく説明するように、ワンホットエンコーディングはデータサイズを大幅に増加させる\n",
    "\n",
    "上記の出力を使用して、以下の質問に答える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ内でカーディナリティが10より大きいカテゴリ変数はいくつありますか？\n",
    "high_cardinality_numcols = 3\n",
    "\n",
    "# 訓練データ内の'Neighborhood'変数をワンホットエンコードするには何列必要ですか？\n",
    "num_cols_neighborhood = 25\n",
    "\n",
    "# Kaggle環境での回答確認用（コメントアウト）\n",
    "# step_3.a.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_3.a.hint()\n",
    "#step_3.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多くの行を持つ大規模なデータセットでは、ワンホットエンコーディングによってデータセットのサイズが大幅に拡大する可能性がある。このため、通常はカーディナリティが比較的低い列のみをワンホットエンコードする。そして、カーディナリティが高い列はデータセットから削除するか、ラベルエンコーディングを使用する。\n",
    "\n",
    "ワンホットエンコーディングとカーディナリティの関係\n",
    "\n",
    "なぜカーディナリティが高い変数にワンホットエンコーディングを避けるのか？\n",
    "1. 次元の爆発：カーディナリティが高い変数をワンホットエンコードすると、\n",
    "   元の1列がカテゴリの数だけの列に展開される\n",
    "2. メモリ効率：高カーディナリティ変数のワンホットエンコードは大量のメモリを消費する\n",
    "3. 計算コスト：列数の増加により、モデルの訓練時間が大幅に増加する\n",
    "4. 過学習リスク：特徴量が増えすぎると、モデルが訓練データに過剰適合する可能性が高まる\n",
    "\n",
    "実際の選択基準：\n",
    "- カーディナリティが低い（通常10未満）：ワンホットエンコーディングが適切\n",
    "- カーディナリティが高い：ラベルエンコーディングか、重要でなければ削除を検討\n",
    "\n",
    "例として、10,000行のデータセットで、100のユニークなエントリを持つ1つのカテゴリ列を考える。\n",
    "- この列を対応するワンホットエンコーディングに置き換えると、データセットにいくつのエントリが追加されるか？\n",
    "- 代わりに列をラベルエンコーディングに置き換えると、いくつのエントリが追加されるか？\n",
    "\n",
    "回答を使用して、以下の行を埋める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列をワンホットエンコーディングに置き換えることでデータセットに追加されるエントリ数は？\n",
    "# 10,000行 × (100-1)列 = 990,000エントリ\n",
    "# 元の列を削除して100列追加するので、実質99列の増加\n",
    "# \n",
    "# ワンホットエンコーディングの計算方法：\n",
    "# - 元の列：10,000行 × 1列 = 10,000エントリ\n",
    "# - ワンホットエンコード後：10,000行 × 100列 = 1,000,000エントリ\n",
    "# - 純増加：1,000,000 - 10,000 = 990,000エントリ\n",
    "OH_entries_added = 10000 * 99\n",
    "\n",
    "# 列をラベルエンコーディングに置き換えることでデータセットに追加されるエントリ数は？\n",
    "# ラベルエンコーディングは元の列を整数に置き換えるだけなので、追加エントリはない\n",
    "# \n",
    "# ラベルエンコーディングの計算方法：\n",
    "# - 元の列：10,000行 × 1列 = 10,000エントリ\n",
    "# - ラベルエンコード後：10,000行 × 1列 = 10,000エントリ（変わらない）\n",
    "# - 純増加：0エントリ（元の列を置き換えるだけなので増加なし）\n",
    "# \n",
    "# この違いが重要な理由：\n",
    "# - データセットのサイズはメモリ使用量に直結する\n",
    "# - 特徴量の数はモデルの複雑さと訓練時間に影響する\n",
    "# - 実務では、この差が処理可能かどうかの分かれ目になることがある\n",
    "label_entries_added = 0\n",
    "\n",
    "# Kaggle環境での回答確認用（コメントアウト）\n",
    "# step_3.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_3.b.hint()\n",
    "#step_3.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ4: ワンホットエンコーディング\n",
    "\n",
    "## ワンホットエンコーディングとは何か？\n",
    "\n",
    "ワンホットエンコーディングは、カテゴリ変数を複数の二値特徴量（0か1のみの値を持つ列）に変換する手法である。各カテゴリに対して新しい列を作成し、該当するカテゴリの場合は1、それ以外は0を設定する。\n",
    "\n",
    "例：「色」という列に「赤」「青」「緑」という値がある場合\n",
    "- 「色_赤」「色_青」「色_緑」という3つの列に変換\n",
    "- 「赤」のデータは [1, 0, 0]\n",
    "- 「青」のデータは [0, 1, 0]\n",
    "- 「緑」のデータは [0, 0, 1] となる\n",
    "\n",
    "## なぜワンホットエンコーディングが必要なのか？\n",
    "\n",
    "1. **順序関係の排除**: ラベルエンコーディングでは「赤=0, 青=1, 緑=2」のように数値に変換するが、これは「緑>青>赤」という順序関係を暗黙的に導入してしまう。多くのカテゴリでは、このような順序関係は存在しない。ワンホットエンコーディングはこの問題を解決する。\n",
    "\n",
    "2. **線形モデルとの相性**: 線形回帰やロジスティック回帰などの線形モデルは、特徴量の線形結合を学習する。ラベルエンコードされた変数では、カテゴリ間の数値的な差が意味を持ってしまうが、ワンホットエンコーディングではそれぞれのカテゴリが独立した特徴量として扱われる。\n",
    "\n",
    "   なぜこれが重要なのか？線形モデルの数学的な観点から説明すると：\n",
    "   \n",
    "   - 線形モデルは基本的に `y = w₁x₁ + w₂x₂ + ... + wₙxₙ + b` という形式で予測を行う\n",
    "   - ラベルエンコーディングの場合：例えば「色」が「赤=0, 青=1, 緑=2」とエンコードされると、モデルは「緑」を「赤」の2倍、「青」の2倍として扱う。つまり `w_色 × 2` という重みづけになる\n",
    "   - しかし実際には「緑」は「赤」の2倍ではなく、単に別のカテゴリに過ぎない\n",
    "   - ワンホットエンコーディングでは：\n",
    "     * 「赤」の場合：`w_赤 × 1 + w_青 × 0 + w_緑 × 0`\n",
    "     * 「青」の場合：`w_赤 × 0 + w_青 × 1 + w_緑 × 0`\n",
    "     * 「緑」の場合：`w_赤 × 0 + w_青 × 0 + w_緑 × 1`\n",
    "   - これにより、各カテゴリは独自の重み（w_赤, w_青, w_緑）を持ち、互いに独立して影響を与えることができる\n",
    "\n",
    "   具体例：住宅価格予測において「地域」というカテゴリ変数がある場合\n",
    "   - ラベルエンコード：「都心=0, 郊外=1, 田舎=2」とすると、モデルは「田舎」を「都心」の2倍として扱ってしまう\n",
    "   - 実際には「都心」「郊外」「田舎」は単に異なる地域であり、数値的な大小関係はない\n",
    "   - ワンホットエンコードでは、各地域が独立した特徴量となり、それぞれが住宅価格に与える影響を個別に学習できる\n",
    "\n",
    "3. **決定木との違い**: 決定木ベースのモデル（ランダムフォレストなど）はラベルエンコーディングでも問題なく機能するが、線形モデルではワンホットエンコーディングが必要なことが多い。\n",
    "\n",
    "   なぜ決定木モデルはラベルエンコーディングでも問題ないのか？\n",
    "   \n",
    "   - 決定木の仕組み：決定木は「特徴量Xの値がしきい値Tより大きいか小さいか」という二分岐の連続で予測を行う\n",
    "   - 例えば「色」が「赤=0, 青=1, 緑=2」とラベルエンコードされている場合：\n",
    "     * 決定木は「色 <= 0.5」という分岐で「赤」とそれ以外を分けられる\n",
    "     * 次に「色 <= 1.5」という分岐で「青」と「緑」を分けられる\n",
    "   - つまり、決定木は複数の分岐を使って、ラベルエンコードされた値を効果的に「カテゴリ」として扱える\n",
    "   - 決定木は特徴量の「順序」ではなく「値によるデータの分割」に基づいて学習するため、ラベルエンコードでも問題ない\n",
    "\n",
    "   ランダムフォレストなどのアンサンブル手法も、基本的に決定木の集合であるため、同様の理由でラベルエンコーディングで効果的に機能する。\n",
    "\n",
    "   対照的に、線形モデルは特徴量の「値」と「重み」の積の和で予測するため、カテゴリ変数の数値表現に敏感であり、ワンホットエンコーディングが必要になる。\n",
    "\n",
    "## ワンホットエンコーディングの欠点\n",
    "\n",
    "1. **次元の増加**: カテゴリの数だけ新しい列が増えるため、データの次元が大幅に増加する。\n",
    "\n",
    "2. **スパース性**: 多くの0と少数の1からなる「スパース」なデータになり、計算効率が低下する場合がある。\n",
    "\n",
    "3. **メモリ消費**: カーディナリティが高い変数では、非常に多くのメモリを消費する。\n",
    "\n",
    "このステップでは、ワンホットエンコーディングを試す。ただし、データセット内のすべてのカテゴリ変数をエンコードするのではなく、カーディナリティが10未満の列に対してのみワンホットエンコーディングを作成する。これは上記の欠点を考慮した実用的なアプローチである。\n",
    "\n",
    "以下のコードセルを変更せずに実行して、ワンホットエンコードされる列を含むPythonリスト`low_cardinality_cols`を設定する。同様に、`high_cardinality_cols`にはデータセットから削除されるカテゴリ列のリストが含まれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Neighborhood', 'Exterior1st', 'Exterior2nd']\n"
     ]
    }
   ],
   "source": [
    "# ワンホットエンコードされる列\n",
    "# カーディナリティが10未満の列を選択\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# データセットから削除される列\n",
    "# 集合の差集合演算で、すべてのカテゴリ列から低カーディナリティ列を引く\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のコードセルを使用して、`X_train`と`X_valid`のデータをワンホットエンコードする。前処理されたDataFrameをそれぞれ`OH_X_train`と`OH_X_valid`に設定する。\n",
    "\n",
    "- データセット内のカテゴリ列の完全なリストはPythonリスト`object_cols`にある。\n",
    "- `low_cardinality_cols`のカテゴリ列のみをワンホットエンコードする必要がある。他のすべてのカテゴリ列はデータセットから削除する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OneHotEncoderを初期化\n",
    "# handle_unknown='ignore': 未知のカテゴリに対してエラーを発生させない\n",
    "# sparse_output=False: 密な配列を返す（デフォルトはスパース行列）\n",
    "# 注意: scikit-learnの新しいバージョンでは、sparse=Falseではなくsparse_output=Falseを使用する\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# 低カーディナリティ列をワンホットエンコード\n",
    "# なぜfit_transformとtransformを分けるのか？\n",
    "# 1. fit_transform: エンコーダーがカテゴリと数値のマッピングを学習し、変換も行う\n",
    "#    - 訓練データでのみ使用し、カテゴリの種類と順序を記憶する\n",
    "# 2. transform: 既に学習したマッピングを使って変換のみを行う\n",
    "#    - 検証データや未知データに適用する際に使用\n",
    "#    - 訓練データと同じマッピングを保証するため重要\n",
    "#\n",
    "# この一貫性がなぜ重要か？\n",
    "# - 機械学習モデルは特徴量の位置に基づいて学習するため、\n",
    "#   訓練と予測で特徴量の順序や意味が変わると正しく予測できない\n",
    "# - 例：訓練データで「色_赤」が3列目、「色_青」が4列目なら、\n",
    "#   検証データでも同じ位置関係を維持する必要がある\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# ワンホットエンコーディングによりインデックスが削除されたので、元に戻す\n",
    "# なぜインデックスを戻す必要があるのか？\n",
    "# 1. OneHotEncoderはnumpy配列を返すため、元のDataFrameのインデックス情報が失われる\n",
    "# 2. 後でconcatする際に、インデックスが一致していないとデータが正しく結合されない\n",
    "# 3. 元のインデックスには行の識別情報（例：住宅ID）が含まれている可能性がある\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# カテゴリ列を削除（ワンホットエンコーディングに置き換える）\n",
    "# なぜすべてのカテゴリ列（object_cols）を削除するのか？\n",
    "# 1. 低カーディナリティ列はワンホットエンコード済みで別途追加するため\n",
    "# 2. 高カーディナリティ列は前述の理由（メモリ消費、次元の爆発）で除外するため\n",
    "# 3. 元のカテゴリ列をそのまま残すと、同じ情報が重複して含まれることになる\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# 数値特徴量にワンホットエンコードされた列を追加\n",
    "# なぜconcatを使うのか？\n",
    "# 1. 数値特徴量とワンホットエンコードされた特徴量を横方向（列方向）に結合するため\n",
    "# 2. axis=1は列方向の結合を指定（axis=0は行方向の結合）\n",
    "# 3. これにより、元の数値特徴量とカテゴリ特徴量の両方の情報を保持したデータセットが作成される\n",
    "#\n",
    "# この結合後のデータセットの特徴：\n",
    "# - すべての数値特徴量が含まれる\n",
    "# - カーディナリティが低いカテゴリ変数がワンホットエンコードされて含まれる\n",
    "# - カーディナリティが高いカテゴリ変数は除外されている\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# 列名をすべて文字列に変換\n",
    "# なぜ必要か？\n",
    "# 1. OneHotEncoderは数値の列名を生成し、pd.DataFrameに変換すると列名に整数型が使われる\n",
    "# 2. 元のnum_X_trainの列名は文字列型\n",
    "# 3. pd.concatで結合すると、列名に整数型と文字列型が混在する\n",
    "# 4. scikit-learnは列名の型が混在していると「TypeError: Feature names are only supported if all input features have string names」エラーを出す\n",
    "# 5. 列名をすべて文字列型に統一することでエラーを解消できる\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "\n",
    "# Kaggle環境での回答確認用（コメントアウト）\n",
    "# step_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_4.hint()\n",
    "#step_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このアプローチのMAEを取得するために次のコードセルを実行する。\n",
    "\n",
    "## ワンホットエンコーディングの効果を評価する\n",
    "\n",
    "ここでは、ワンホットエンコーディングを使用したアプローチの性能を評価する。これにより、以下の点が明らかになる：\n",
    "\n",
    "1. **カテゴリ変数の表現方法による影響**：\n",
    "   - ラベルエンコーディング（順序関係を暗黙的に導入）\n",
    "   - ワンホットエンコーディング（各カテゴリを独立した特徴として表現）\n",
    "   のどちらが予測精度に良い影響を与えるか\n",
    "\n",
    "2. **カーディナリティによる選択的処理の効果**：\n",
    "   - 低カーディナリティ列のみをワンホットエンコード\n",
    "   - 高カーディナリティ列を削除\n",
    "   という選択が妥当かどうか\n",
    "\n",
    "3. **モデルとエンコーディング手法の相性**：\n",
    "   - ランダムフォレスト（決定木ベース）はラベルエンコーディングでも効果的に機能するが、\n",
    "     ワンホットエンコーディングでさらに性能が向上するか\n",
    "   - 線形モデルであれば、ワンホットエンコーディングの効果はより顕著になる可能性がある\n",
    "\n",
    "結果を見ることで、どのエンコーディング手法が最も効果的かを判断できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "17525.345719178084\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ5: テスト予測を生成し、結果を提出する\n",
    "\n",
    "ステップ4を完了した後、学んだことを使用してリーダーボードに結果を提出したい場合は、予測を生成する前にテストデータを前処理する必要がある。\n",
    "\n",
    "**このステップは完全にオプションであり、エクササイズを正常に完了するためにリーダーボードに結果を提出する必要はない。**\n",
    "\n",
    "[コンペティションに参加する](https://www.kaggle.com/c/home-data-for-ml-course)方法や結果をCSVに保存する方法を思い出すのに助けが必要な場合は、前のエクササイズを確認してください。結果ファイルを生成したら、以下の手順に従ってください：\n",
    "- 右上隅の青い**COMMIT**ボタンをクリックする。これによりポップアップウィンドウが生成される。\n",
    "- コードの実行が終了したら、ポップアップウィンドウの右上にある青い**Open Version**ボタンをクリックする。これにより、同じページのビューモードに移動する。これらの指示に戻るには下にスクロールする必要がある。\n",
    "- 画面左側の**Output**タブをクリックする。次に、**Submit to Competition**ボタンをクリックして、結果をリーダーボードに提出する。\n",
    "- パフォーマンスを向上させるためにさらに作業を続けたい場合は、画面右上の青い**Edit**ボタンを選択する。その後、モデルを変更してプロセスを繰り返すことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの欠損値を0で埋める\n",
    "# なぜ欠損値を0で埋めるのか？\n",
    "# 1. 一貫性の確保：訓練データと同じ前処理をテストデータにも適用する必要がある\n",
    "#    - 訓練データでも欠損値を0で埋めていた場合、テストデータも同様に処理する\n",
    "# 2. モデルの期待：モデルは訓練時に見た形式のデータを予測時にも期待する\n",
    "#    - 訓練時と異なる形式のデータを与えると、予測精度が低下する可能性がある\n",
    "# 3. 実用的な選択：単純な方法だが、多くの場合で十分に機能する\n",
    "#\n",
    "# 代替手法：\n",
    "# - 平均値や中央値での補完：数値的に意味のある値で置き換える\n",
    "# - 高度な補完手法：KNN、回帰モデル、多重代入法などを使用\n",
    "# - 特別な値の使用：欠損を示す特別な値（例：-999）を使用し、別途「欠損フラグ」列を追加\n",
    "X_test.fillna(0, inplace=True)\n",
    "\n",
    "# すべてのカテゴリ列\n",
    "# なぜX_testではなくXを使うのか？\n",
    "# 1. 一貫性の確保：訓練データ（X）で識別したカテゴリ列と同じ列をテストデータでも処理する\n",
    "# 2. 完全性：テストデータには訓練データにあるカテゴリが存在しない可能性がある\n",
    "# 3. モデルの期待：モデルは訓練データの構造に基づいて学習しているため、\n",
    "#    テストデータも同じ構造にする必要がある\n",
    "object_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n",
    "\n",
    "# 安全にラベルエンコードできる列\n",
    "# テストデータの値が訓練データの値のサブセットであることを確認\n",
    "# なぜこのチェックが重要なのか？\n",
    "# 1. エンコーディングの安全性：ラベルエンコーダーは訓練データで見たカテゴリのみを変換できる\n",
    "# 2. エラー回避：テストデータに新しいカテゴリがあると、変換時にエラーが発生する\n",
    "# 3. 予測の信頼性：訓練データに存在しないカテゴリは、モデルが学習していないため\n",
    "#    適切に予測できない可能性が高い\n",
    "#\n",
    "# issubset()の意味：\n",
    "# - set(X_test[col]).issubset(set(X[col])) は「テストデータの値がすべて訓練データに含まれているか」を確認\n",
    "# - これにより、安全にエンコードできる列だけを選択できる\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_test[col]).issubset(set(X[col]))]\n",
    "        \n",
    "# データセットから削除される問題のある列\n",
    "# なぜ問題のある列を削除するのか？\n",
    "# 1. エラー回避：新しいカテゴリ値があるとエンコーディング時にエラーが発生する\n",
    "# 2. 予測の安定性：訓練データに存在しないカテゴリを含む列は予測に悪影響を与える可能性がある\n",
    "# 3. 実用的な選択：複雑なカスタムエンコーダーを作成するよりも、単純に削除する方が実装が容易\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "\n",
    "# エンコードされないカテゴリ列を削除\n",
    "# なぜ訓練データ全体（X）を使うのか？\n",
    "# 1. 最終モデルの構築：これまでの分析では訓練データと検証データを分けていたが、\n",
    "#    最終モデルでは全データを使用するのが一般的\n",
    "# 2. データ量の最大化：より多くのデータでモデルを訓練することで、一般化性能が向上する\n",
    "# 3. 実世界での予測：実際のコンペティションや本番環境では、利用可能なすべてのデータを\n",
    "#    使ってモデルを訓練するのが標準的\n",
    "label_X = X.drop(bad_label_cols, axis=1)\n",
    "label_X_test = X_test.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# ラベルエンコーダーを適用\n",
    "# なぜ各列に対して新しいエンコーダーインスタンスを使うのか？\n",
    "# 1. 列ごとの独立性：各カテゴリ列は独自のカテゴリセットを持つため、個別にエンコードする必要がある\n",
    "# 2. マッピングの一貫性：各列内でのカテゴリ→数値のマッピングを一貫させるため\n",
    "# 3. エンコーダーの仕様：LabelEncoderは単一の特徴（列）に対してのみ動作するよう設計されている\n",
    "labelEncoder = LabelEncoder()\n",
    "for col in good_label_cols:\n",
    "    # 全訓練データでエンコーダーをフィットし、変換\n",
    "    # なぜfit_transformとtransformを分けるのか？\n",
    "    # 1. 学習と適用の分離：訓練データでカテゴリ→数値のマッピングを学習し、\n",
    "    #    そのマッピングをテストデータに適用する\n",
    "    # 2. データリーク防止：テストデータの情報を使ってエンコーダーを学習させると、\n",
    "    #    未来の情報を使って過去を予測することになり、不適切\n",
    "    # 3. 一貫性の確保：同じカテゴリに対して常に同じ数値を割り当てる必要がある\n",
    "    label_X[col] = labelEncoder.fit_transform(X[col])\n",
    "    # テストデータを変換（フィットはしない）\n",
    "    label_X_test[col] = labelEncoder.transform(X_test[col])\n",
    "\n",
    "# 200の決定木を持つモデル、MAE: 15923.57616\n",
    "#\n",
    "# このノートブックの目的：住宅価格の予測\n",
    "# - 様々な特徴（カテゴリ変数を含む）から住宅の販売価格（SalePrice）を予測する\n",
    "# - これまでのステップでは、カテゴリ変数の処理方法（削除、ラベルエンコード、ワンホットエンコード）を比較した\n",
    "# - ステップ5では、最適な方法を使って最終的なモデルを構築し、テストデータに対する予測を生成する\n",
    "#\n",
    "# ランダムフォレストを使う理由：\n",
    "# - 複雑な非線形関係を捉えられる（住宅特性と価格の関係は単純な線形関係ではない）\n",
    "# - カテゴリ変数と数値変数の両方を効果的に扱える\n",
    "# - 外れ値に対して堅牢（不動産市場には極端に高価な物件などが存在する可能性がある）\n",
    "# - 特徴量の重要度を評価できる（どの特徴が価格に最も影響するかを分析できる）\n",
    "#\n",
    "# n_estimators=200（決定木の数）を選んだ理由：\n",
    "# 1. 予測精度の向上：決定木を増やすと、個々の木の誤差が平均化され、より正確な価格予測が可能になる\n",
    "#    - 前のステップでは100本の決定木を使用していたが、最終モデルでは200本に増やして精度を向上\n",
    "# 2. 過学習の防止：複数の木を使うことで、訓練データに過剰適合するリスクを減らし、\n",
    "#    未知の物件に対しても信頼性の高い価格予測ができる\n",
    "# 3. 経験則：住宅価格予測のような複雑な問題では、200本程度の決定木が良いバランスを提供する\n",
    "#\n",
    "# 注意点：\n",
    "# - 決定木の数を増やすと計算コストも増加する（大規模なデータセットでは考慮が必要）\n",
    "# - ある程度以上増やしても予測精度の向上が頭打ちになる場合が多い\n",
    "# - 理想的には、クロスバリデーションを使って最適な木の数を決定する\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "model.fit(label_X, y)\n",
    "\n",
    "# テスト予測を取得\n",
    "# なぜmodel.predictを使うのか？\n",
    "# 1. 学習済みモデルの活用：fit()で学習したモデルのパターンを使って新しいデータを予測する\n",
    "# 2. 推論フェーズ：訓練（fit）と予測（predict）は機械学習の2つの主要フェーズ\n",
    "# 3. 回帰問題：住宅価格予測は回帰問題なので、predict()は各サンプルに対する連続値（価格）を返す\n",
    "#\n",
    "# 予測値の解釈：\n",
    "# - 各行（住宅）に対する予測価格が返される\n",
    "# - 予測値の単位は目的変数（y）と同じ（この場合はドル）\n",
    "# - 予測値は小数点を含む連続値として返される\n",
    "preds_test = model.predict(label_X_test)\n",
    "\n",
    "# テスト予測をファイルに保存\n",
    "# なぜこの形式で保存するのか？\n",
    "# 1. コンペティション要件：Kaggleコンペティションでは特定の形式での提出が求められる\n",
    "#    - 通常、'Id'列と予測対象の列（ここでは'SalePrice'）が必要\n",
    "# 2. インデックスの活用：label_X_test.indexを使うことで、元のデータの識別子を保持できる\n",
    "# 3. フォーマット要件：index=Falseを指定することで、DataFrameのインデックスを別列として\n",
    "#    出力せず、Kaggleの要求する形式に合わせている\n",
    "#\n",
    "# CSVフォーマットを選ぶ理由：\n",
    "# - 互換性：ほとんどのシステムで読み込み可能な標準フォーマット\n",
    "# - 人間可読性：テキストエディタで開いて内容を確認できる\n",
    "# - Kaggle標準：多くのKaggleコンペティションでCSV形式での提出が求められる\n",
    "output = pd.DataFrame({'Id': label_X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 次のステップ\n",
    "\n",
    "欠損値の処理とカテゴリエンコーディングにより、モデリングプロセスは複雑になっている。この複雑さは、将来使用するためにモデルを保存したい場合にさらに悪化する。この複雑さを管理するための鍵は**パイプライン**と呼ばれるものだ。\n",
    "\n",
    "**[パイプラインの使用方法を学ぶ](https://www.kaggle.com/alexisbcook/pipelines)**で、カテゴリ変数、欠損値、およびデータが投げかけるその他の厄介な問題を含むデータセットを前処理する方法を学ぼう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[中級機械学習ホームページ](https://www.kaggle.com/learn/intermediate-machine-learning)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*質問やコメントがありますか？[Learn Discussion forum](https://www.kaggle.com/learn-forum)で他の学習者とチャットしましょう。*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
