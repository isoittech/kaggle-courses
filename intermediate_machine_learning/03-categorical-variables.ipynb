{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[中級機械学習ホームページ](https://www.kaggle.com/learn/intermediate-machine-learning)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**カテゴリ変数**をエンコードすることで、これまでで最良の結果が得られる！\n",
    "\n",
    "# セットアップ\n",
    "\n",
    "以下の質問は作業に対するフィードバックを提供する。フィードバックシステムを設定するために次のセルを実行しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle学習環境のコード確認設定\n",
    "# from learntools.core import binder\n",
    "# binder.bind(globals())\n",
    "# from learntools.ml_intermediate.ex3 import *\n",
    "# print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このエクササイズでは、[Kaggle学習ユーザー向け住宅価格コンペティション](https://www.kaggle.com/c/home-data-for-ml-course)のデータを使用する。\n",
    "\n",
    "![Ames住宅データセット画像](https://i.imgur.com/lTJVG4e.png)\n",
    "\n",
    "次のコードセルを変更せずに実行して、訓練セットと検証セットを`X_train`、`X_valid`、`y_train`、`y_valid`に読み込む。テストセットは`X_test`に読み込まれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  test.csv.gz  train.csv  train.csv.gz\n",
      "---------------\n",
      "test.csv  test.csv.gz  train.csv  train.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# --- データファイルの展開と確認 ---\n",
    "#   データディレクトリ内のファイル一覧を表示する。\n",
    "!ls ./input/Housing-Prices \n",
    "!echo \"---------------\"\n",
    "# !gzip -d -c ./input/Housing-Prices/train.csv.gz > ./input/Housing-Prices/train.csv\n",
    "#   train.csv.gz（圧縮ファイル）を解凍してtrain.csvを作成する。\n",
    "!gzip -d -c ./input/Housing-Prices/train.csv.gz > ./input/Housing-Prices/train.csv\n",
    "# !gzip -d -c ./input/Housing-Prices/test.csv.gz > ./input/Housing-Prices/test.csv\n",
    "#   test.csv.gz（圧縮ファイル）を解凍してtest.csvを作成する。\n",
    "!gzip -d -c ./input/Housing-Prices/test.csv.gz > ./input/Housing-Prices/test.csv\n",
    "# !ls ./input/Housing-Prices\n",
    "#   再度ファイル一覧を表示し、解凍後のファイルが存在するか確認する。\n",
    "!ls ./input/Housing-Prices \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの読み込み\n",
    "# index_col='Id'でIDを行インデックスとして設定\n",
    "X = pd.read_csv('../input/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "# 目的変数が欠損している行を削除し、目的変数と説明変数を分離\n",
    "# dropna: 欠損値を含む行を削除\n",
    "# axis=0: 行方向の削除\n",
    "# subset=['SalePrice']: SalePriceが欠損している行のみを対象\n",
    "# inplace=True: 元のデータフレームを変更\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "# 目的変数（住宅価格）を取り出す\n",
    "y = X.SalePrice\n",
    "# 説明変数から目的変数の列を削除\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# シンプルにするため、欠損値を含む列を削除\n",
    "# リスト内包表記を使用: X.columns内の各列colに対して、X[col].isnull().any()がTrueなら列名を取得\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# 訓練データから検証データを分割\n",
    "# train_size=0.8: 訓練データに80%を使用\n",
    "# test_size=0.2: 検証データに20%を使用\n",
    "# random_state=0: 再現性のための乱数シード\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のコードセルを使用して、データの最初の5行を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11694</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>6600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>13360</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13265</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                        \n",
       "619          20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
       "871          20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
       "93           30       RL    13360   Pave      IR1         HLS    AllPub   \n",
       "818          20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
       "303          20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "    LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "Id                                    ...                                       \n",
       "619    Inside       Gtl      NridgHt  ...         108             0         0   \n",
       "871    Inside       Gtl        NAmes  ...           0             0         0   \n",
       "93     Inside       Gtl      Crawfor  ...           0            44         0   \n",
       "818   CulDSac       Gtl      Mitchel  ...          59             0         0   \n",
       "303    Corner       Gtl      CollgCr  ...          81             0         0   \n",
       "\n",
       "    ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
       "Id                                                                         \n",
       "619         260         0        0       7    2007      New       Partial  \n",
       "871           0         0        0       8    2009       WD        Normal  \n",
       "93            0         0        0       8    2009       WD        Normal  \n",
       "818           0         0        0       7    2008       WD        Normal  \n",
       "303           0         0        0       1    2006       WD        Normal  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head()メソッドでデータフレームの先頭5行を表示\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットには数値変数とカテゴリ変数の両方が含まれていることに注目。モデルを訓練する前にカテゴリデータをエンコードする必要がある。\n",
    "\n",
    "異なるモデルを比較するために、チュートリアルと同じ`score_dataset()`関数を使用する。この関数はランダムフォレストモデルから[平均絶対誤差](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE)を報告する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 異なるアプローチを比較するための関数\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    # ランダムフォレスト回帰モデルを初期化（100本の決定木、乱数シード0）\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    # モデルを訓練データにフィット（学習）させる\n",
    "    model.fit(X_train, y_train)\n",
    "    # 検証データに対する予測を生成\n",
    "    preds = model.predict(X_valid)\n",
    "    # 予測値と実際の値の平均絶対誤差を計算して返す\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ1: カテゴリデータを含む列を削除する\n",
    "\n",
    "最も単純なアプローチから始める。以下のコードセルを使用して、`X_train`と`X_valid`のデータを前処理し、カテゴリデータを含む列を削除する。前処理されたDataFrameをそれぞれ`drop_X_train`と`drop_X_valid`に設定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_Drop\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練データと検証データからカテゴリ列を削除\n",
    "# select_dtypes(exclude=['object'])で文字列型（オブジェクト型）の列を除外\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Kaggle環境での回答確認用コード（コメントアウト）\n",
    "# step_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_1.hint()\n",
    "#step_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このアプローチのMAEを取得するために次のコードセルを実行する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ2: ラベルエンコーディング\n",
    "\n",
    "ラベルエンコーディングに進む前に、データセットを調査する。具体的には、`'Condition2'`列を見てみる。以下のコードセルは、訓練セットと検証セットの両方でのユニークな値を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "# unique()メソッドで列内のユニークな値を取得\n",
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、以下のコードを書いた場合：\n",
    "- 訓練データにラベルエンコーダーをフィットし、\n",
    "- それを使って訓練データと検証データの両方を変換する\n",
    "\n",
    "エラーが発生する。なぜこれが問題になるか分かるだろうか？（この質問に答えるには、上記の出力を使用する必要がある）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle環境でのヒント表示用（コメントアウト）\n",
    "# step_2.a.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"2.1_LabelA\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> Fitting a label encoder to a column in the training data creates a corresponding integer-valued label for each unique value **that appears in the training data**. In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them.  Notice that the `'Condition2'` column in the validation data contains the values `'RRAn'` and `'RRNn'`, but these don't appear in the training data -- thus, if we try to use a label encoder with scikit-learn, the code will throw an error."
      ],
      "text/plain": [
       "Solution: Fitting a label encoder to a column in the training data creates a corresponding integer-valued label for each unique value **that appears in the training data**. In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them.  Notice that the `'Condition2'` column in the validation data contains the values `'RRAn'` and `'RRNn'`, but these don't appear in the training data -- thus, if we try to use a label encoder with scikit-learn, the code will throw an error."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Kaggle環境での解答表示用（コメントアウト）\n",
    "# step_2.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは実世界のデータでよく遭遇する一般的な問題であり、この問題を解決するためのアプローチは多数ある。例えば、新しいカテゴリに対応するカスタムラベルエンコーダーを作成することができる。しかし、最も単純なアプローチは、問題のあるカテゴリ列を削除することだ。\n",
    "\n",
    "以下のコードセルを実行して、問題のある列をPythonリスト`bad_label_cols`に保存する。同様に、安全にラベルエンコードできる列は`good_label_cols`に格納される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be label encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'BldgType', 'HouseStyle', 'ExterQual', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Neighborhood', 'RoofStyle', 'ExterCond', 'Functional', 'Condition2', 'Heating', 'Exterior2nd', 'RoofMatl', 'Utilities', 'Foundation', 'LandSlope', 'HeatingQC', 'Condition1', 'SaleType', 'Exterior1st']\n"
     ]
    }
   ],
   "source": [
    "# すべてのカテゴリ列\n",
    "# dtype == \"object\"でカテゴリ（文字列）型の列を特定\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# 安全にラベルエンコードできる列\n",
    "# 訓練データと検証データで同じ値のセットを持つ列\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# データセットから削除される問題のある列\n",
    "# 集合の差集合演算で、すべてのカテゴリ列から安全な列を引く\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコードセルを使用して、`X_train`と`X_valid`のデータをラベルエンコードする。前処理されたDataFrameをそれぞれ`label_X_train`と`label_X_valid`に設定する。\n",
    "\n",
    "- `bad_label_cols`のカテゴリ列をデータセットから削除するコードを提供している。\n",
    "- `good_label_cols`のカテゴリ列をラベルエンコードする必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2.2_LabelB\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# エンコードされないカテゴリ列を削除\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# ラベルエンコーダーを適用\n",
    "labelEncoder = LabelEncoder()\n",
    "for col in good_label_cols:\n",
    "    # 訓練データでエンコーダーをフィットし、変換\n",
    "    label_X_train[col] = labelEncoder.fit_transform(X_train[col])\n",
    "    # 検証データを変換（フィットはしない）\n",
    "    label_X_valid[col] = labelEncoder.transform(X_valid[col])\n",
    "    \n",
    "# Kaggle環境での回答確認用（コメントアウト）\n",
    "# step_2.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_2.b.hint()\n",
    "#step_2.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このアプローチのMAEを取得するために次のコードセルを実行する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Label Encoding):\n",
      "17575.291883561644\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ3: カーディナリティの調査\n",
    "\n",
    "これまで、カテゴリ変数を扱うための2つの異なるアプローチを試した。そして、カテゴリデータをエンコードすることが、データセットから列を削除するよりも良い結果をもたらすことがわかった。\n",
    "\n",
    "次に、ワンホットエンコーディングを試す。その前に、もう一つ追加のトピックをカバーする必要がある。まず、次のコードセルを変更せずに実行する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# カテゴリデータを持つ各列のユニークな値の数を取得\n",
    "# map関数で各列に対してnunique()を適用\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "# 列名とユニーク値数の辞書を作成\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# 列ごとのユニークな値の数を昇順で表示\n",
    "# sorted関数でキーの値（ユニーク値の数）に基づいてソート\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の出力は、カテゴリデータを持つ各列について、その列のユニークな値の数を示している。例えば、訓練データの`'Street'`列には、砂利道を表す`'Grvl'`と舗装道路を表す`'Pave'`という2つのユニークな値がある。\n",
    "\n",
    "カテゴリ変数のユニークな値の数を、そのカテゴリ変数の**カーディナリティ**と呼ぶ。例えば、`'Street'`変数のカーディナリティは2である。\n",
    "\n",
    "上記の出力を使用して、以下の質問に答える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3.1_CardinalityA\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練データ内でカーディナリティが10より大きいカテゴリ変数はいくつありますか？\n",
    "high_cardinality_numcols = 3\n",
    "\n",
    "# 訓練データ内の'Neighborhood'変数をワンホットエンコードするには何列必要ですか？\n",
    "num_cols_neighborhood = 25\n",
    "\n",
    "# Kaggle環境での回答確認用（コメントアウト）\n",
    "# step_3.a.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_3.a.hint()\n",
    "#step_3.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多くの行を持つ大規模なデータセットでは、ワンホットエンコーディングによってデータセットのサイズが大幅に拡大する可能性がある。このため、通常はカーディナリティが比較的低い列のみをワンホットエンコードする。そして、カーディナリティが高い列はデータセットから削除するか、ラベルエンコーディングを使用する。\n",
    "\n",
    "例として、10,000行のデータセットで、100のユニークなエントリを持つ1つのカテゴリ列を考える。\n",
    "- この列を対応するワンホットエンコーディングに置き換えると、データセットにいくつのエントリが追加されるか？\n",
    "- 代わりに列をラベルエンコーディングに置き換えると、いくつのエントリが追加されるか？\n",
    "\n",
    "回答を使用して、以下の行を埋める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3.2_CardinalityB\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 列をワンホットエンコーディングに置き換えることでデータセットに追加されるエントリ数は？\n",
    "# 10,000行 × (100-1)列 = 990,000エントリ\n",
    "# 元の列を削除して100列追加するので、実質99列の増加\n",
    "OH_entries_added = 10000 * 99\n",
    "\n",
    "# 列をラベルエンコーディングに置き換えることでデータセットに追加されるエントリ数は？\n",
    "# ラベルエンコーディングは元の列を整数に置き換えるだけなので、追加エントリはない\n",
    "label_entries_added = 0\n",
    "\n",
    "# Kaggle環境での回答確認用（コメントアウト）\n",
    "# step_3.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_3.b.hint()\n",
    "#step_3.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ4: ワンホットエンコーディング\n",
    "\n",
    "このステップでは、ワンホットエンコーディングを試す。ただし、データセット内のすべてのカテゴリ変数をエンコードするのではなく、カーディナリティが10未満の列に対してのみワンホットエンコーディングを作成する。\n",
    "\n",
    "以下のコードセルを変更せずに実行して、ワンホットエンコードされる列を含むPythonリスト`low_cardinality_cols`を設定する。同様に、`high_cardinality_cols`にはデータセットから削除されるカテゴリ列のリストが含まれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Neighborhood', 'Exterior2nd', 'Exterior1st']\n"
     ]
    }
   ],
   "source": [
    "# ワンホットエンコードされる列\n",
    "# カーディナリティが10未満の列を選択\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# データセットから削除される列\n",
    "# 集合の差集合演算で、すべてのカテゴリ列から低カーディナリティ列を引く\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のコードセルを使用して、`X_train`と`X_valid`のデータをワンホットエンコードする。前処理されたDataFrameをそれぞれ`OH_X_train`と`OH_X_valid`に設定する。\n",
    "\n",
    "- データセット内のカテゴリ列の完全なリストはPythonリスト`object_cols`にある。\n",
    "- `low_cardinality_cols`のカテゴリ列のみをワンホットエンコードする必要がある。他のすべてのカテゴリ列はデータセットから削除する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"4_OneHot\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OneHotEncoderを初期化\n",
    "# handle_unknown='ignore': 未知のカテゴリに対してエラーを発生させない\n",
    "# sparse=False: 密な配列を返す（デフォルトはスパース行列）\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# 低カーディナリティ列をワンホットエンコード\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# ワンホットエンコーディングによりインデックスが削除されたので、元に戻す\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# カテゴリ列を削除（ワンホットエンコーディングに置き換える）\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# 数値特徴量にワンホットエンコードされた列を追加\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# Kaggle環境での回答確認用（コメントアウト）\n",
    "# step_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒントや解答コードを表示するための行（Kaggle環境用）\n",
    "#step_4.hint()\n",
    "#step_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このアプローチのMAEを取得するために次のコードセルを実行する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "17525.345719178084\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ5: テスト予測を生成し、結果を提出する\n",
    "\n",
    "ステップ4を完了した後、学んだことを使用してリーダーボードに結果を提出したい場合は、予測を生成する前にテストデータを前処理する必要がある。\n",
    "\n",
    "**このステップは完全にオプションであり、エクササイズを正常に完了するためにリーダーボードに結果を提出する必要はない。**\n",
    "\n",
    "[コンペティションに参加する](https://www.kaggle.com/c/home-data-for-ml-course)方法や結果をCSVに保存する方法を思い出すのに助けが必要な場合は、前のエクササイズを確認してください。結果ファイルを生成したら、以下の手順に従ってください：\n",
    "- 右上隅の青い**COMMIT**ボタンをクリックする。これによりポップアップウィンドウが生成される。\n",
    "- コードの実行が終了したら、ポップアップウィンドウの右上にある青い**Open Version**ボタンをクリックする。これにより、同じページのビューモードに移動する。これらの指示に戻るには下にスクロールする必要がある。\n",
    "- 画面左側の**Output**タブをクリックする。次に、**Submit to Competition**ボタンをクリックして、結果をリーダーボードに提出する。\n",
    "- パフォーマンスを向上させるためにさらに作業を続けたい場合は、画面右上の青い**Edit**ボタンを選択する。その後、モデルを変更してプロセスを繰り返すことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be label encoded: ['Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['MSZoning', 'KitchenQual', 'Functional', 'Exterior2nd', 'Utilities', 'SaleType', 'Exterior1st']\n"
     ]
    }
   ],
   "source": [
    "# テストデータの欠損値を0で埋める\n",
    "X_test.fillna(0, inplace=True)\n",
    "\n",
    "# すべてのカテゴリ列\n",
    "object_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n",
    "\n",
    "# 安全にラベルエンコードできる列\n",
    "# テストデータの値が訓練データの値のサブセットであることを確認\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_test[col]).issubset(set(X[col]))]\n",
    "        \n",
    "# データセットから削除される問題のある列\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "\n",
    "# エンコードされないカテゴリ列を削除\n",
    "label_X = X.drop(bad_label_cols, axis=1)\n",
    "label_X_test = X_test.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# ラベルエンコーダーを適用\n",
    "labelEncoder = LabelEncoder()\n",
    "for col in good_label_cols:\n",
    "    # 全訓練データでエンコーダーをフィットし、変換\n",
    "    label_X[col] = labelEncoder.fit_transform(X[col])\n",
    "    # テストデータを変換\n",
    "    label_X_test[col] = labelEncoder.transform(X_test[col])\n",
    "\n",
    "# 200の決定木を持つモデル、MAE: 15923.57616\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "model.fit(label_X, y)\n",
    "\n",
    "# テスト予測を取得\n",
    "preds_test = model.predict(label_X_test)\n",
    "\n",
    "# テスト予測をファイルに保存\n",
    "output = pd.DataFrame({'Id': label_X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 次のステップ\n",
    "\n",
    "欠損値の処理とカテゴリエンコーディングにより、モデリングプロセスは複雑になっている。この複雑さは、将来使用するためにモデルを保存したい場合にさらに悪化する。この複雑さを管理するための鍵は**パイプライン**と呼ばれるものだ。\n",
    "\n",
    "**[パイプラインの使用方法を学ぶ](https://www.kaggle.com/alexisbcook/pipelines)**で、カテゴリ変数、欠損値、およびデータが投げかけるその他の厄介な問題を含むデータセットを前処理する方法を学ぼう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[中級機械学習ホームページ](https://www.kaggle.com/learn/intermediate-machine-learning)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*質問やコメントがありますか？[Learn Discussion forum](https://www.kaggle.com/learn-forum)で他の学習者とチャットしましょう。*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
